{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reimplement Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "#Extracting\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    text = \"\"\n",
    "    with open(pdf_file, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)  # Use PdfReader instead of PdfFileReader\n",
    "        for page_num in range(len(reader.pages)):  # reader.pages gives a list of pages\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "book1 = extract_text_from_pdf(r\"C:\\Users\\Admin\\Downloads\\#Semester 7\\NLP - Natural Language Processing\\Gr homework\\group 4\\NLP-group-4\\Data\\1. Harry Potter and the Philosopher's Stone.pdf\")\n",
    "book2 = extract_text_from_pdf(r\"C:\\Users\\Admin\\Downloads\\#Semester 7\\NLP - Natural Language Processing\\Gr homework\\group 4\\NLP-group-4\\Data\\2. Harry Potter and the Chamber of Secrets.pdf\")\n",
    "book3 = extract_text_from_pdf(r\"C:\\Users\\Admin\\Downloads\\#Semester 7\\NLP - Natural Language Processing\\Gr homework\\group 4\\NLP-group-4\\Data\\3. Harry Potter and the Prisoner of Azkaban.pdf\")\n",
    "book4 = extract_text_from_pdf(r\"C:\\Users\\Admin\\Downloads\\#Semester 7\\NLP - Natural Language Processing\\Gr homework\\group 4\\NLP-group-4\\Data\\4. Harry Potter and the Goblet.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text Preprocessing:\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "processed_text1 = preprocess_text(book1)\n",
    "processed_text2 = preprocess_text(book2)\n",
    "processed_text3 = preprocess_text(book3)\n",
    "processed_text4 = preprocess_text(book4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Document Matrix (Raw Frequency):\n",
      "[[ 1  1  1 ...  2  0  1]\n",
      " [ 1  1  1 ...  0  0  0]\n",
      " [ 1  1  1 ...  3  0  0]\n",
      " [ 1  1  1 ... 11  1  3]]\n",
      "\n",
      "Terms (Features):\n",
      "['10' '100' '101' ... 'zooming' 'éclair' 'éclairs']\n",
      "\n",
      "Execution Time: 0.6097168922424316 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def ensure_string(text):\n",
    "    if isinstance(text, list):\n",
    "        return ' '.join(text)  \n",
    "\n",
    "def build_term_document_matrix(documents):\n",
    "    vectorizer = CountVectorizer() \n",
    "    X = vectorizer.fit_transform(documents)  \n",
    "    return X, vectorizer.get_feature_names_out()  \n",
    "\n",
    "documents = [\n",
    "    ensure_string(processed_text1),\n",
    "    ensure_string(processed_text2),\n",
    "    ensure_string(processed_text3),\n",
    "    ensure_string(processed_text4)\n",
    "]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "term_document_matrix, terms = build_term_document_matrix(documents)\n",
    "\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "\n",
    "print(\"Term-Document Matrix (Raw Frequency):\")\n",
    "print(term_document_matrix.toarray()) \n",
    "\n",
    "print(\"\\nTerms (Features):\")\n",
    "print(terms)  \n",
    "\n",
    "print(f\"\\nExecution Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance Matrix:\n",
      " [[   0.          916.1129843  1463.21256146 3420.60564813]\n",
      " [ 916.1129843     0.         1134.279507   2952.26082859]\n",
      " [1463.21256146 1134.279507      0.         2456.55042692]\n",
      " [3420.60564813 2952.26082859 2456.55042692    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Euclidean Distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "euclidean_dist = euclidean_distances(term_document_matrix)\n",
    "print(\"Euclidean Distance Matrix:\\n\", euclidean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      " [[1.         0.94329679 0.9416178  0.93467331]\n",
      " [0.94329679 1.         0.95078986 0.95214857]\n",
      " [0.9416178  0.95078986 1.         0.94577085]\n",
      " [0.93467331 0.95214857 0.94577085 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Consine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(term_document_matrix)\n",
    "print(\"Cosine Similarity Matrix:\\n\", cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Document Matrix for Selected Words:\n",
      "    wizard  magical  harry  spells  witch  journey\n",
      "0      42       11   1308       6     12       11\n",
      "1      47       16   1633       9     16        5\n",
      "2      39       31   2035       2     42        6\n",
      "3      83      125   3134      24     37       10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "documents = [' '.join(processed_text1), \n",
    "             ' '.join(processed_text2), \n",
    "             ' '.join(processed_text3), \n",
    "             ' '.join(processed_text4)]\n",
    "\n",
    "representative_words = ['wizard', 'magical', 'harry', 'spells', 'witch', 'journey']\n",
    "\n",
    "# Create a CountVectorizer with the selected words\n",
    "vectorizer = CountVectorizer(vocabulary = representative_words)\n",
    "term_document_matrix = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "df = pd.DataFrame(term_document_matrix, columns = representative_words)\n",
    "print(\"Term-Document Matrix for Selected Words:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix for Selected Words:\n",
      " [[1.         0.99997861 0.99980603 0.99946822]\n",
      " [0.99997861 1.         0.9998701  0.99954149]\n",
      " [0.99980603 0.9998701  1.         0.999609  ]\n",
      " [0.99946822 0.99954149 0.999609   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(term_document_matrix)\n",
    "print(\"Cosine Similarity Matrix for Selected Words:\\n\", cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Embeddings:\n",
      " [[1308.55565611  -23.64973942]\n",
      " [1633.60579063  -26.99254366]\n",
      " [2035.79150708  -26.59805943]\n",
      " [3137.64510112   41.17428047]]\n"
     ]
    }
   ],
   "source": [
    "# Reduce dimensionality using Truncated SVD\n",
    "n_components = 2\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "reduced_embeddings = svd.fit_transform(term_document_matrix)\n",
    "\n",
    "print(\"Reduced Embeddings:\\n\", reduced_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main task 2: Implement tf-idf to replace the raw frequency of the term-doc matrix in Question 1. Recompute the similarity between 4 Harry Potter books with cosine similarity metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part combines both ways for easy comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Document Matrix with Raw Frequency:\n",
      "   10  100  101  102  103  104  105  106  107  108  ...  zombie  zonko  \\\n",
      "0   1    1    1    1    1    1    1    1    0    1  ...       2      0   \n",
      "1   1    1    1    1    1    1    1    1    0    1  ...       0      0   \n",
      "2   1    1    1    1    1    1    1    1    0    1  ...       1     11   \n",
      "3   1    1    1    1    1    1    1    0    1    1  ...       0      1   \n",
      "\n",
      "   zontal  zoo  zoological  zoom  zoomed  zooming  éclair  éclairs  \n",
      "0       0    7           0     1       1        2       0        1  \n",
      "1       0    2           0     0       2        0       0        0  \n",
      "2       0    0           0     0       9        3       0        0  \n",
      "3       1    0           1     4       9       11       1        3  \n",
      "\n",
      "[4 rows x 15458 columns]\n",
      "\n",
      "Cosine Similarity Matrix with Raw Frequency:\n",
      "          Book 1    Book 2    Book 3    Book 4\n",
      "Book 1  1.000000  0.943297  0.941618  0.934673\n",
      "Book 2  0.943297  1.000000  0.950790  0.952149\n",
      "Book 3  0.941618  0.950790  1.000000  0.945771\n",
      "Book 4  0.934673  0.952149  0.945771  1.000000\n",
      "\n",
      "TF-IDF Matrix:\n",
      "         10       100       101       102       103       104       105  \\\n",
      "0  0.000475  0.000475  0.000475  0.000475  0.000475  0.000475  0.000475   \n",
      "1  0.000384  0.000384  0.000384  0.000384  0.000384  0.000384  0.000384   \n",
      "2  0.000302  0.000302  0.000302  0.000302  0.000302  0.000302  0.000302   \n",
      "3  0.000185  0.000185  0.000185  0.000185  0.000185  0.000185  0.000185   \n",
      "\n",
      "        106       107       108  ...    zombie     zonko    zontal       zoo  \\\n",
      "0  0.000581  0.000000  0.000475  ...  0.001436  0.000000  0.000000  0.005026   \n",
      "1  0.000469  0.000000  0.000384  ...  0.000000  0.000000  0.000000  0.001160   \n",
      "2  0.000370  0.000000  0.000302  ...  0.000457  0.005024  0.000000  0.000000   \n",
      "3  0.000000  0.000355  0.000185  ...  0.000000  0.000280  0.000355  0.000000   \n",
      "\n",
      "   zoological      zoom    zoomed   zooming    éclair   éclairs  \n",
      "0    0.000000  0.000718  0.000475  0.001163  0.000000  0.000718  \n",
      "1    0.000000  0.000000  0.000768  0.000000  0.000000  0.000000  \n",
      "2    0.000000  0.000000  0.002721  0.001109  0.000000  0.000000  \n",
      "3    0.000355  0.001118  0.001665  0.002489  0.000355  0.000839  \n",
      "\n",
      "[4 rows x 15458 columns]\n",
      "\n",
      "Cosine Similarity Matrix with TF-IDF:\n",
      "          Book 1    Book 2    Book 3    Book 4\n",
      "Book 1  1.000000  0.924907  0.920044  0.909882\n",
      "Book 2  0.924907  1.000000  0.922645  0.923897\n",
      "Book 3  0.920044  0.922645  1.000000  0.913766\n",
      "Book 4  0.909882  0.923897  0.913766  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Preprocessed documents (from your previous code)\n",
    "documents = [' '.join(processed_text1), \n",
    "             ' '.join(processed_text2), \n",
    "             ' '.join(processed_text3), \n",
    "             ' '.join(processed_text4)]\n",
    "\n",
    "# 1. Raw Frequency (CountVectorizer)\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_matrix = count_vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "# Calculate Cosine Similarity with Raw Frequency\n",
    "cosine_sim_raw = cosine_similarity(count_matrix)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "count_df = pd.DataFrame(count_matrix, columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"Term-Document Matrix with Raw Frequency:\")\n",
    "print(count_df)\n",
    "print(\"\\nCosine Similarity Matrix with Raw Frequency:\")\n",
    "print(pd.DataFrame(cosine_sim_raw, index=[f'Book {i+1}' for i in range(4)], columns=[f'Book {i+1}' for i in range(4)]))\n",
    "\n",
    "\n",
    "# 2. TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "# Calculate Cosine Similarity with TF-IDF\n",
    "cosine_sim_tfidf = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_df)\n",
    "print(\"\\nCosine Similarity Matrix with TF-IDF:\")\n",
    "print(pd.DataFrame(cosine_sim_tfidf, index=[f'Book {i+1}' for i in range(4)], columns=[f'Book {i+1}' for i in range(4)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Raw Frequency: This matrix is based on the frequency of the words in each document, but does not take into account the importance of the word in each document, resulting in common words that can blur the differences between books.\n",
    "=> Tends to give higher similarity values for documents that share a lot of common words, even if those words are not particularly important or representative.\n",
    "- TF-IDF:When using TF-IDF, words that appear more in one document but less in other documents will have a higher weight. This helps improve the distinction between books\n",
    "=> Lowers the similarity for common words and focuses more on terms that are specific to a given document, resulting in a more meaningful similarity measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Implement Pointwise Mutual Information (PMI) to replace the raw frequency of the term-doc matrix in Question 1. Recompute the similarity between 4 Harry Potter books with cosine similarity metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PMI Matrix:\n",
      "             10       100       101       102       103       104       105  \\\n",
      "Doc 1  0.603341  0.603341  0.603341  0.603341  0.603341  0.603341  0.603341   \n",
      "Doc 2  0.416718  0.416718  0.416718  0.416718  0.416718  0.416718  0.416718   \n",
      "Doc 3  0.087057  0.087057  0.087057  0.087057  0.087057  0.087057  0.087057   \n",
      "Doc 4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "            106       107       108  ...    zombie     zonko    zontal  \\\n",
      "Doc 1  1.018379  0.000000  0.603341  ...  2.018379  0.000000  0.000000   \n",
      "Doc 2  0.831756  0.000000  0.416718  ...  0.000000  0.000000  0.000000   \n",
      "Doc 3  0.502094  0.000000  0.087057  ...  0.502094  1.961526  0.000000   \n",
      "Doc 4  0.000000  1.276481  0.000000  ...  0.000000  0.000000  1.276481   \n",
      "\n",
      "            zoo  zoological      zoom    zoomed   zooming    éclair   éclairs  \n",
      "Doc 1  2.240771    0.000000  0.281413  0.000000  0.000000  0.000000  0.603341  \n",
      "Doc 2  0.246793    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "Doc 3  0.000000    0.000000  0.000000  0.864664  0.000000  0.000000  0.000000  \n",
      "Doc 4  0.000000    1.276481  0.954553  0.054089  0.735913  1.276481  0.861444  \n",
      "\n",
      "[4 rows x 15458 columns]\n",
      "\n",
      "Cosine Similarity Matrix with PMI:\n",
      "          Book 1    Book 2    Book 3    Book 4\n",
      "Book 1  1.000000  0.074969  0.063808  0.029099\n",
      "Book 2  0.074969  1.000000  0.072751  0.033506\n",
      "Book 3  0.063808  0.072751  1.000000  0.030217\n",
      "Book 4  0.029099  0.033506  0.030217  1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Create the term-document frequency matrix\n",
    "def build_term_document_matrix(documents):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(documents)\n",
    "    return X.toarray(), vectorizer.get_feature_names_out()\n",
    "\n",
    "# Step 2: Calculate PMI for the term-document matrix\n",
    "def compute_pmi(term_doc_matrix):\n",
    "    # Total word occurrences in all documents\n",
    "    total_word_count = np.sum(term_doc_matrix)\n",
    "    \n",
    "    # Calculate the frequency of each word (P(w))\n",
    "    word_freq = np.sum(term_doc_matrix, axis=0)\n",
    "    \n",
    "    # Calculate the frequency of each document (P(d))\n",
    "    doc_freq = np.sum(term_doc_matrix, axis=1)\n",
    "    \n",
    "    # Calculate joint probability P(w, d) = frequency of word w in document d / total word occurrences\n",
    "    joint_prob = term_doc_matrix / total_word_count\n",
    "    \n",
    "    # Calculate PMI\n",
    "    pmi_matrix = np.zeros_like(term_doc_matrix, dtype=float)\n",
    "    \n",
    "    for i in range(term_doc_matrix.shape[0]):  # Iterate over documents\n",
    "        for j in range(term_doc_matrix.shape[1]):  # Iterate over words\n",
    "            if term_doc_matrix[i, j] > 0:\n",
    "                # Compute PMI(w, d) = log2(P(w, d) / (P(w) * P(d)))\n",
    "                p_w = word_freq[j] / total_word_count  # Probability of word w\n",
    "                p_d = doc_freq[i] / total_word_count  # Probability of document d\n",
    "                pmi_value = np.log2(joint_prob[i, j] / (p_w * p_d))\n",
    "                pmi_matrix[i, j] = max(pmi_value, 0)  # Apply PPMI (Positive PMI) to remove negative values\n",
    "    \n",
    "    return pmi_matrix\n",
    "\n",
    "# Step 3: Compute cosine similarity for the PMI matrix\n",
    "def cosine_similarity_pmi(documents):\n",
    "    term_doc_matrix, terms = build_term_document_matrix(documents)\n",
    "    pmi_matrix = compute_pmi(term_doc_matrix)\n",
    "    cosine_sim_pmi = cosine_similarity(pmi_matrix)\n",
    "    return cosine_sim_pmi, pmi_matrix, terms\n",
    "\n",
    "# Step 4: Integrate the steps and compare 4 books\n",
    "documents = [\n",
    "    ' '.join(processed_text1),\n",
    "    ' '.join(processed_text2),\n",
    "    ' '.join(processed_text3),\n",
    "    ' '.join(processed_text4)\n",
    "]\n",
    "\n",
    "# Calculate cosine similarity using the PMI matrix\n",
    "cosine_sim_pmi, pmi_matrix, terms = cosine_similarity_pmi(documents)\n",
    "\n",
    "# Display the PMI matrix\n",
    "print(\"\\nPMI Matrix:\")\n",
    "pmi_df = pd.DataFrame(pmi_matrix, columns=terms, index=[f'Doc {i+1}' for i in range(pmi_matrix.shape[0])])\n",
    "print(pmi_df)\n",
    "\n",
    "# Display the cosine similarity matrix\n",
    "print(\"\\nCosine Similarity Matrix with PMI:\")\n",
    "cosine_df = pd.DataFrame(cosine_sim_pmi, index=[f'Book {i+1}' for i in range(4)], \n",
    "                         columns=[f'Book {i+1}' for i in range(4)])\n",
    "print(cosine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
